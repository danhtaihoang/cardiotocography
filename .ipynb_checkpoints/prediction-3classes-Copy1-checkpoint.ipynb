{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import ER_multiclass as ER\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "X = np.loadtxt('../cardiotocography_X_cleaned.txt')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2126)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y12 = np.loadtxt('../cardiotocography_y_cleaned.txt')\n",
    "y12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y12[1]  # NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " array([384, 579,  53,  81,  72, 332, 252, 107,  69, 197]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(X_train,y_train,X_test,y_test,method='expectation_reflection'):\n",
    "    if method == 'expectation_reflection':\n",
    "        h0,w = ER.fit(X_train,y_train,niter_max=100,regu=0.0)\n",
    "        y_pred = ER.predict(X_test,h0,w)\n",
    "\n",
    "    else:\n",
    "        if method == 'logistic_regression':\n",
    "            model = LogisticRegression(multi_class='multinomial',solver='saga')\n",
    "\n",
    "        if method == 'naive_bayes': \n",
    "            model = GaussianNB()\n",
    "\n",
    "        if method == 'random_forest':\n",
    "            model = RandomForestClassifier(criterion = \"gini\", random_state = 1,\n",
    "                           max_depth=3, min_samples_leaf=5,n_estimators=100)   \n",
    "            \n",
    "        if method == 'decision_tree':\n",
    "            model = DecisionTreeClassifier()  \n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "    accuracy = accuracy_score(y_test,y_pred)                \n",
    "                  \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_inference(X,y,train_size):\n",
    "    npred = 100\n",
    "    accuracy = np.zeros((len(list_methods),npred))\n",
    "    precision = np.zeros((len(list_methods),npred))\n",
    "    recall = np.zeros((len(list_methods),npred))\n",
    "    accuracy_train = np.zeros((len(list_methods),npred))\n",
    "    for ipred in range(npred):\n",
    "        X_train0,X_test,y_train0,y_test = train_test_split(X,y,test_size=0.2,random_state = ipred)\n",
    "\n",
    "        idx_train = np.random.choice(len(y_train0),size=int(train_size*len(y)),replace=False)\n",
    "        X_train,y_train = X_train0[idx_train],y_train0[idx_train]\n",
    "\n",
    "        for i,method in enumerate(list_methods):\n",
    "            accuracy[i,ipred] = inference(X_train,y_train,X_test,y_test,method)\n",
    "            \n",
    "    return accuracy.mean(axis=1),accuracy.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 [0.75112676 0.49685446 0.74992958 0.76784038]\n",
      "0.6 [0.73960094 0.48941315 0.74978873 0.76328638]\n"
     ]
    }
   ],
   "source": [
    "list_train_size = [0.8,0.6,0.4,0.2]\n",
    "list_methods=['logistic_regression','naive_bayes','random_forest','expectation_reflection']\n",
    "acc = np.zeros((len(list_train_size),len(list_methods)))\n",
    "acc_std = np.zeros((len(list_train_size),len(list_methods)))\n",
    "for i,train_size in enumerate(list_train_size):\n",
    "    acc[i,:],acc_std[i,:] = compare_inference(X,y,train_size)\n",
    "    print(train_size,acc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(acc,columns = list_methods)\n",
    "df.insert(0, \"train_size\",list_train_size, True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))    \n",
    "plt.plot(list_train_size,acc[:,0],'k--',marker='o',mfc='none',label='Logistic Regression')\n",
    "plt.plot(list_train_size,acc[:,1],'b--',marker='s',mfc='none',label='Naive Bayes')\n",
    "plt.plot(list_train_size,acc[:,2],'r--',marker='^',mfc='none',label='Random Forest')\n",
    "plt.plot(list_train_size,acc[:,-1],'k-',marker='o',label='Expectation Reflection')\n",
    "plt.xlabel('train size')\n",
    "plt.ylabel('accuracy mean')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))    \n",
    "plt.plot(list_train_size,acc_std[:,0],'k--',marker='o',mfc='none',label='Logistic Regression')\n",
    "plt.plot(list_train_size,acc_std[:,1],'b--',marker='s',mfc='none',label='Naive Bayes')\n",
    "plt.plot(list_train_size,acc_std[:,2],'r--',marker='^',mfc='none',label='Random Forest')\n",
    "plt.plot(list_train_size,acc_std[:,-1],'k-',marker='o',label='Expectation Reflection')\n",
    "plt.xlabel('train size')\n",
    "plt.ylabel('accuracy standard deviation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('cardiotocography_acc.txt',acc,fmt='%f')\n",
    "np.savetxt('cardiotocography_acc_std.txt',acc_std,fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
